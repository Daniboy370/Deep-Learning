{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"RCNN_video.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-5NBe6iAxPr1","colab_type":"text"},"source":["# First Step\n","\n","This notebook shows step-by-step the implementation I used for my video. Any input video is valid, but note that its focus should be found in one of the \n","MS-COCO pre-trained classes. Class recognition is capable by choice in the 'apply_mask' section, where the extracted label should be defined."]},{"cell_type":"code","metadata":{"id":"fUFqakqwxPr3","colab_type":"code","outputId":"31b5758b-61f2-435e-bae0-636754c50058","executionInfo":{"status":"ok","timestamp":1589179770913,"user_tz":-180,"elapsed":1074,"user":{"displayName":"Daniboy370","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisFuHNjZVpGvNFUt6wihcx57PEaP-JkIvLEz5EGf4=s64","userId":"01810773580519398826"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# pip install ffpyplayer\n","import cv2, os, sys\n","import numpy as np\n","\n","from google.colab import drive\n","path = '/content/drive/My Drive/Colab Notebooks/Object Detection/Mask_RCNN'\n","path_PARENT = '/content/drive/My Drive/Colab Notebooks/Object Detection'\n","drive.mount('/content/drive')\n","\n","if os.getcwd() != path:\n","    os.chdir(path)\n","\n","from samples import coco\n","from mrcnn import utils\n","from mrcnn import model as modellib\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b-4ilnscxPr9","colab_type":"text"},"source":["# Pretrained model and configuration info\n","\n","Loading the pre-trained model data ([Mask-RCNN](https://github.com/matterport/Mask_RCNN/releases) trained by COCO dataset), \\\\\n","and carefully fitting the right paths to the CURRENT working directory."]},{"cell_type":"code","metadata":{"id":"y2qFvpTBxPr-","colab_type":"code","colab":{}},"source":["# Load the pre-trained model data\n","ROOT_DIR = os.getcwd()\n","# Download pretrained net @ https://github.com/matterport/Mask_RCNN/releases\n","COCO_MODEL_PATH = os.path.join(path_PARENT, 'mask_rcnn_coco.h5')\n","\n","if not os.path.exists(COCO_MODEL_PATH):\n","    utils.download_trained_weights(COCO_MODEL_PATH)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eZ_d1T5exPsC","colab_type":"text"},"source":["The original configuration information is saved in config.py file. It can be changed if necessary. \n","\n","It's better to use the default value, but you can also change the GPU information to suit the personal GPU well."]},{"cell_type":"code","metadata":{"id":"dA8-jf-pxPsC","colab_type":"code","colab":{}},"source":["# Change the config infermation\n","class InferenceConfig(coco.CocoConfig):\n","    GPU_COUNT = 1\n","    \n","    # Number of images to train with on each GPU. A 12GB GPU can typically\n","    # handle 2 images of 1024x1024px.\n","    # Adjust based on your GPU memory and image sizes. Use the highest\n","    # number that your GPU can handle for best performance.\n","    IMAGES_PER_GPU = 1\n","    \n","config = InferenceConfig()\n","# config.print()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4U6adsGxPsG","colab_type":"code","colab":{}},"source":["# COCO dataset object names\n","model = modellib.MaskRCNN(mode=\"inference\", model_dir=COCO_MODEL_PATH, config=config)\n","model.load_weights(COCO_MODEL_PATH, by_name=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mi6W1k7s-ne6","colab_type":"code","colab":{}},"source":["\n","class_names = [\n","    'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n","    'bus', 'train', 'truck', 'boat', 'traffic light',\n","    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n","    'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n","    'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n","    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n","    'kite', 'baseball bat', 'baseball glove', 'skateboard',\n","    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n","    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n","    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n","    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n","    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n","    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n","    'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n","    'teddy bear', 'hair drier', 'toothbrush']\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZAiZYsnLxPsK","colab_type":"text"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","# Define the processing functions\n","\n","Now define two image process functions to process each frame of the input video. \n","\n","apply_mask is used to change the background information to grayscale.\n","\n","display_instances is used to show the object detection result in original image."]},{"cell_type":"code","metadata":{"id":"RPuG9fqtxPsK","colab_type":"code","colab":{}},"source":["def apply_mask(image, mask):\n","    \"\"\" This function receives the detected RCNN's frame with its label map.\n","    It seperates the desired label from the rest of the frame which is automatically\n","    coloured at black and white. I chose to colorize the 'person' label, though\n","    any label ( @ class_names ) is feasible.\n","    \"\"\"\n","    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    image[:, :, 0] = np.where( mask == 0, gray_image[:, :], image[:, :, 0]) # R\n","    image[:, :, 1] = np.where( mask == 0, gray_image[:, :], image[:, :, 1]) # G\n","    image[:, :, 2] = np.where( mask == 0, gray_image[:, :], image[:, :, 2]) # B\n","    return image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xGDSm01GxPsN","colab_type":"code","colab":{}},"source":["def display_instances(image, boxes, masks, ids, names, scores):\n","    \"\"\" This function utilizes for extracting the detection results from\n","    the original image. Note that the max_area will save the largest object\n","     for all the detection results\"\"\"\n","\n","    max_area = 0\n","    \n","    # n_instances saves the amount of all objects\n","    n_instances = boxes.shape[0]\n","\n","    if not n_instances:\n","        print('NO INSTANCES TO DISPLAY')\n","    else:\n","        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n","\n","    for i in range(n_instances):\n","        if not np.any(boxes[i]):\n","            continue\n","\n","        # compute the square of each object\n","        y1, x1, y2, x2 = boxes[i]\n","        square = (y2 - y1) * (x2 - x1)\n","\n","        label = names[ids[i]]\n","        if label == 'person':\n","            # save the largest object in the image as main character\n","            # other people will be regarded as background\n","            if square > max_area:\n","                max_area = square\n","                mask = masks[:, :, i]\n","            else:\n","                continue\n","        else:\n","            continue\n","\n","        # apply mask for the image\n","        image = apply_mask(image, mask)\n","        \n","    return image"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g9kqoU6UxPsQ","colab_type":"text"},"source":["# Process Video\n","\n","The following script is the main call, using the openCV video capture tools, \\\\\n","calling the Mask RCNN detection tools at each frame of the footage. \\\\\n","Eventually it is save to the cuttent working directory."]},{"cell_type":"code","metadata":{"id":"yrvEdPf9xPsR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"52c4bb8f-8d2e-4f47-cc1c-dff1e4ee3260","executionInfo":{"status":"ok","timestamp":1589180263147,"user_tz":-180,"elapsed":493256,"user":{"displayName":"Daniboy370","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisFuHNjZVpGvNFUt6wihcx57PEaP-JkIvLEz5EGf4=s64","userId":"01810773580519398826"}}},"source":["from google.colab.patches import cv2_imshow\n","\n","input_video = 'Aladdin_low_res.mp4'\n","cap = cv2.VideoCapture(input_video)\n","\n","# Recording Video\n","fps = cap.get(cv2.CAP_PROP_FPS)  # Find original frames rate\n","width, height = int(cap.get(3)), int(cap.get(4))\n","fcc = cv2.VideoWriter_fourcc('D', 'I', 'V', 'X')\n","vid_out = cv2.VideoWriter(\"video_output.avi\", fcc, fps, (width, height))\n","\n","# ----- Extracting desired footage segments ----- #\n","fr_i = 0\n","fr_tot = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","fr_0_a, fr_end_a = 0.205*fr_tot, 0.321*fr_tot\n","# fr_0_b, fr_end_b = 0.800*fr_tot, 0.936*fr_tot\n","\n","while fr_i < fr_tot:\n","    ret, frame = cap.read()\n","\n","    # ----- Desirable segment for detection ----- #\n","    # if ( (fr_i > fr_0_a) & (fr_i < fr_end_a) ) | ( (fr_i > fr_0_b) & (fr_i < fr_end_b) ) :\n","    if ( (fr_i > fr_0_a) & (fr_i < fr_end_a) ):\n","        # ---------- Print live index ----------- #    \n","        if fr_i % 25 == 0:\n","            print(\"Progress: {:.2f} [%]\".format( 100*(fr_i - fr_0_a)/(fr_end_a - fr_0_a) ))\n","        # ------- Activate CNN detection -------- # \n","        results = model.detect([frame], verbose=0)\n","        r = results[0]\n","        frame = display_instances(\n","            frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])\n","        # cv2_imshow(frame)         # uncomment for online presentation\n","        vid_out.write(frame)        # Recording Video\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","    \n","    fr_i += 1\n","\n","# -------- Close and Save video footage --------- #\n","cap.release()\n","vid_out.release()\n","cv2.destroyAllWindows()\n"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Progress: 3.19 [%]\n","Progress: 7.37 [%]\n","Progress: 11.56 [%]\n","Progress: 15.74 [%]\n","Progress: 19.92 [%]\n","Progress: 24.11 [%]\n","Progress: 28.29 [%]\n","Progress: 32.48 [%]\n","Progress: 36.66 [%]\n","Progress: 40.84 [%]\n","Progress: 45.03 [%]\n","Progress: 49.21 [%]\n","Progress: 53.40 [%]\n","Progress: 57.58 [%]\n","Progress: 61.76 [%]\n","Progress: 65.95 [%]\n","Progress: 70.13 [%]\n","Progress: 74.32 [%]\n","Progress: 78.50 [%]\n","Progress: 82.68 [%]\n","Progress: 86.87 [%]\n","Progress: 91.05 [%]\n","Progress: 95.24 [%]\n","Progress: 99.42 [%]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IWTga_VOyI__","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}